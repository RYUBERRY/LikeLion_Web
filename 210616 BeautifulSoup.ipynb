{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "* ESC + M : 마크다운 만들기\n",
    "* ESC + Y : 소스코드 실행 셀 만들기\n",
    "* ESC + A : 위에 셀 추가\n",
    "* ESC + B : 아래 셀 추가\n",
    "* ESC + X : 셀 삭제\n",
    "* SHIFT + Enter : 셀 실행 셀 추가\n",
    "* CTRL + Enter : 셀 실행 (현재 위치에 그대로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p>test</p></body></html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body><p>test</p></body></html>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test</p>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title>나의 웹페이지</title></head>\n",
    "<p>test1</p>\n",
    "<p>test2</p>\n",
    "<p>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>나의 웹페이지</title></head>\n",
       "<body><p>test1</p>\n",
       "<p>test2</p>\n",
       "<p>test3</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 요소 가져오기 : soup.요소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><p>test1</p>\n",
       "<p>test2</p>\n",
       "<p>test3</p>\n",
       "</body>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그러나, .요소로 불러올 경우에는 제일 상위 요소만 가져오게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test1</p>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>나의 웹페이지</title></head>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_all()  여러개의 요소 한번에 가져오기\n",
    "무조건 list 형식으로 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>test1</p>, <p>test2</p>, <p>test3</p>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find_all() 지정 요소 가져오기, [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"class1\">test2</p>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title> test site</title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p calss='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 1\n",
    "1) p 요소 전부 가져오기\n",
    "2) span 요소 전부 가져오기\n",
    "3) head 요소 전부 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 정보 찾을 때 예외 케이스\n",
    "* 태그가 화면상에서는 보이지 않을 때 ex)class = blind\n",
    "* 페이지 소스 코드 보기를 이용하여 찾는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title> test site</title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p calss='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test2</p>,\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " <p calss=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"class3\">span tag text</span>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<head><title> test site</title></head>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find()  요소 한개씩 가져오기, 문자열!로 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title> test site</title></head>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title> test site</title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p calss='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> test site</title>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class 이름으로 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\",class_ = \"class1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id 이름으로 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"p1\">오늘의 주가지수 1500</p>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", id=\"p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 번에 걸쳐서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title> test site</title></head>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = soup.find(\"head\")\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> test site</title>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = soup.find(\"title\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test site'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습2\n",
    "\n",
    "### 1) div 두번째 요소의 안의 첫번째 p태그 전체 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<p id=\"p1\">오늘의 주가지수 1500</p>\n",
       "<p class=\"class4\">test3</p>\n",
       "<span class=\"class3\">span tag text</span>\n",
       "</div>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div2 = soup.find_all('div')[1]\n",
    "div2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"p1\">오늘의 주가지수 1500</p>, <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = div2.find_all(\"p\")\n",
    "p_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) div 첫번째 요소의 안의 첫번째 p태그 요소 가져오기\n",
    "(간략하게 압축해서 코드 쓰기) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1 = soup.find(\"div\").find(\"p\")\n",
    "div1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find_all 에서는 .find이어서 사용 못함 [0]인덱스 붙여서 지정해야함\n",
    "#### find에서만 .find , /find_all 이어서 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) a태그의 모든 url을 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <a href=\"https://www.google.com\">구글</a>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com\n",
      "https://www.naver.com/\n",
      "https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "urls = soup.find_all(\"a\")\n",
    "\n",
    "for url in urls:\n",
    "    #print(url)\n",
    "    print(url.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://www.google.com'}\n",
      "https://www.google.com\n",
      "{'href': 'https://www.naver.com/'}\n",
      "https://www.naver.com/\n",
      "{'href': 'https://www.daum.com/'}\n",
      "https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "urls = soup.find_all(\"a\")\n",
    "\n",
    "for url in urls:\n",
    "    print(url.attrs)  #attrs 딕셔너리 형태로 가져와서 key값으로 뽑아내는 방법\n",
    "    print(url.attrs[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .prettify() 예쁘게 보여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   test site\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p align=\"left\" class=\"class1\">\n",
      "   test3\n",
      "  </p>\n",
      "  <p class=\"class1\">\n",
      "   test2\n",
      "  </p>\n",
      "  <p id=\"p1\">\n",
      "   오늘의 주가지수 1500\n",
      "  </p>\n",
      "  <span class=\"class3\">\n",
      "   span tag text\n",
      "  </span>\n",
      "  <p class=\"class4\">\n",
      "   test3\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head><title> test site </title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print( soup.prettify() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## children 활용\n",
    "* 자신의 요소의 자식들의 요소를 가지고 올 수 있다.\n",
    "* content속성(or contents)을 이용하여 가져올 수도 있음.\n",
    "* 기타 parents, next_sibling, next_elements 등이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <a href=\"https://www.google.com\">구글</a>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<a href=\"https://www.google.com\">구글</a>\n",
       "<p align=\"left\" class=\"class1\">test3</p>\n",
       "<p class=\"class1\">test2</p>\n",
       "</div>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1 = soup.find(\"div\")\n",
    "div1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x1b8d4267520>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <a href=\"https://www.google.com\">구글</a>,\n",
       " '\\n',\n",
       " <p align=\"left\" class=\"class1\">test3</p>,\n",
       " '\\n',\n",
       " <p class=\"class1\">test2</p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(div1.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"class1\">test2</p>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1_lastp = list(div1.children)[5]\n",
    "div1_lastp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습3\n",
    "### children 속성을 이용해서 span 태그 요소를 가져와 보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<p id=\"p1\">오늘의 주가지수 1500</p>\n",
       "<p class=\"class4\">test3</p>\n",
       "<span class=\"class3\">span tag text</span>\n",
       "<a href=\"https://www.naver.com/\">네이버</a>\n",
       "<a href=\"https://www.daum.com/\">다음</a>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div2 = soup.find_all(\"div\")[1]\n",
    "div2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x1b8d4267940>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div2.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " '\\n',\n",
       " <p class=\"class4\">test3</p>,\n",
       " '\\n',\n",
       " <span class=\"class3\">span tag text</span>,\n",
       " '\\n',\n",
       " <a href=\"https://www.naver.com/\">네이버</a>,\n",
       " '\\n',\n",
       " <a href=\"https://www.daum.com/\">다음</a>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(div2.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div2_spn = list(div2.children)[5]\n",
    "div2_spn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위의 코드 한줄로 압축해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.find_all('div')[1].children)[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습4\n",
    "### 1) p태그의 text만 가져오기(for문 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <a href=\"https://www.google.com\">구글</a>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test2</p>,\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = soup.find(\"body\").find_all(\"p\")\n",
    "p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3\n",
      "test2\n",
      "오늘의 주가지수 1500\n",
      "test3\n"
     ]
    }
   ],
   "source": [
    "for p_txt in p_all:\n",
    "    print(p_txt.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) a태그의 url 및 text 가져오기(for문 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.google.com\">구글</a>,\n",
       " <a href=\"https://www.naver.com/\">네이버</a>,\n",
       " <a href=\"https://www.daum.com/\">다음</a>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_all = soup.find(\"body\").find_all(\"a\")\n",
    "a_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "list_a = soup.find_all(\"a\")\n",
    "for a_data in list_a:\n",
    "    print(a_data.text, a_data.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위의 내용을 csv 파일로 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n",
      "['구글', '네이버', '다음']\n",
      "['https://www.google.com', 'https://www.naver.com/', 'https://www.daum.com/']\n"
     ]
    }
   ],
   "source": [
    "company = []\n",
    "urls = []\n",
    "\n",
    "list_a = soup.find_all(\"a\")\n",
    "for a_data in list_a:\n",
    "    print(a_data.text, a_data.get(\"href\"))\n",
    "    company.append(a_data.text)\n",
    "    urls.append(a_data.get(\"href\"))\n",
    "    \n",
    "print(company)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv 파일 만들기 - pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas의 기본 자료형\n",
    "* Series\n",
    "* DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>웹사이트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글</td>\n",
       "      <td>https://www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버</td>\n",
       "      <td>https://www.naver.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음</td>\n",
       "      <td>https://www.daum.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   회사명                    웹사이트\n",
       "0   구글  https://www.google.com\n",
       "1  네이버  https://www.naver.com/\n",
       "2   다음   https://www.daum.com/"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = {'회사명':company, '웹사이트':urls}\n",
    "dat = pd.DataFrame(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RYUBERRY\\OneDrive\\문서\\GitHub\\LikeLion_Web\n",
      "['.git', '.gitattributes', '.ipynb_checkpoints', '0614_class_comment.html', '0614_class_CSS 실습.html', '0614_class_CSS.css', '0614_class_CSS.html', '0614_class_heading.html', '0614_class_id.html', '0614_class_list.html', '0614_class_table.html', '210616 BeautifulSoup.ipynb', 'html1.html', 'README.md', '해변.jpg', '회사명과웹사이트.csv']\n"
     ]
    }
   ],
   "source": [
    "dat.to_csv(\"회사명과웹사이트.csv\", index=False)\n",
    "\n",
    "## 확인하기\n",
    "print( os.getcwd() ) #현재 위치\n",
    "print( os.listdir(os.getcwd()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가 문제) ##### https://ldjwj.github.io/00_PYTHON_LEVELUP_CLASS/web_class/index.html \n",
    "#####  * 이 곳의 링크 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습5\n",
    "### 네이버 주식 기본 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>국내증시 : 네이버 금융</title>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "soup.title  #1차적으로 정보 가져온 것 먼저 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"num\" id=\"KOSPI_now\">3,276.26</span>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span', id=\"KOSPI_now\") #코스피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"num\" id=\"KOSDAQ_now\">999.15</span>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span', id=\"KOSDAQ_now\") #코스닥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"num\" id=\"KPI200_now\">436.53</span>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span', id=\"KPI200_now\") #코스피200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3,276.26', '999.15', '436.53')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = soup.findAll('span', id='KOSPI_now')[0].text\n",
    "b = soup.findAll('span', id=\"KOSDAQ_now\")[0].text\n",
    "c = soup.findAll('span', id=\"KPI200_now\")[0].text\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 코스피지수 : 3,276.26\n",
      "현재 코스닥지수 : 999.15\n",
      "현재 코스피200지수 : 436.53\n"
     ]
    }
   ],
   "source": [
    "kospi = soup.find('span', id='KOSPI_now')\n",
    "kosdaq = soup.find('span', id=\"KOSDAQ_now\")\n",
    "kpi200 = soup.find('span', id=\"KPI200_now\")\n",
    "print(\"현재 코스피지수 : {}\".format(kospi.get_text()))\n",
    "print(\"현재 코스닥지수 : {}\".format(kosdaq.get_text()))\n",
    "print(\"현재 코스피200지수 : {}\".format(kpi200.get_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위의 코드 간단하게 압축해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 코스피지수 : 3,277.12\n",
      "현재 코스닥지수 : 999.33\n",
      "현재 코스피200지수 : 436.73\n"
     ]
    }
   ],
   "source": [
    "url = 'https://finance.naver.com/sise/'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "kospi = soup.find_all(\"span\", id=\"KOSPI_now\")[0].text\n",
    "kosdaq = soup.find_all(\"span\", id=\"KOSDAQ_now\")[0].text\n",
    "kpi200 = soup.find_all(\"span\", id=\"KPI200_now\")[0].text\n",
    "print(\"현재 코스피지수 :\", kospi)\n",
    "print(\"현재 코스닥지수 :\", kosdaq)\n",
    "print(\"현재 코스피200지수 :\", kpi200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,277.12 999.33 436.73\n"
     ]
    }
   ],
   "source": [
    "kospi = soup.find('span', id='KOSPI_now').text\n",
    "kosdaq = soup.find('span', id=\"KOSDAQ_now\").text\n",
    "kpi200 = soup.find('span', id=\"KPI200_now\").text\n",
    "\n",
    "print(kospi, kosdaq, kpi200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습6\n",
    "### 네이버금융 인기 검색 종목 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>국내증시 : 네이버 금융</title>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "soup.title "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 해당 정보가 있는 부분을 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li><em>1.</em><a href=\"/item/main.nhn?code=035420\" onclick=\"clickcr(this,'boa.list','035420','1',event)\">NAVER</a><span class=\"up\">394,000</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_stock = soup.find(\"ul\", id=\"popularItemList\")\n",
    "stock_all = search_stock.findAll(\"li\")\n",
    "stock_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. text가 포함된 태그 찾아서 하나 먼저 뽑아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVER\n",
      "394,000\n"
     ]
    }
   ],
   "source": [
    "print(stock_all[0].find(\"a\").text)\n",
    "print(stock_all[0].find(\"span\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.리스트 형식으로 묶어서 전체 text를 결과 뽑아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAVER', '카카오', '삼성전자', '대원전선', '두산중공업', '가비아', 'HMM', '쌍방울', '서울식품', '대한전선']\n",
      "['394,000', '143,000', '81,600', '3,630', '24,900', '19,100', '45,500', '1,270', '466', '3,295']\n"
     ]
    }
   ],
   "source": [
    "com_all = []\n",
    "price_all = []\n",
    "\n",
    "for one in stock_all:\n",
    "    com_one = one.find(\"a\").text\n",
    "    price_one = one.find(\"span\").text\n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)\n",
    "    \n",
    "print(com_all)\n",
    "print(price_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딕셔너리 형태로 가져오는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## naver finance 인기 종목\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "all_pop = soup.find(\"ul\", class_=\"lst_pop\").find_all(\"li\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for li in all_pop:\n",
    "    dic = {}\n",
    "    dic[\"rank\"] = li.find(\"em\").text\n",
    "    dic[\"com\"] = li.find(\"a\").text\n",
    "    dic[\"up_down\"] = li.find('span', class_='blind').text\n",
    "    dic[\"price\"] = li.find('span').text\n",
    "    dic[\"code\"] = li.find('a').get(\"onclick\").split(',')[2].strip(\"''\")\n",
    "    all_data.append(dic)\n",
    "    \n",
    "dat = pd.DataFrame(all_data)\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 네이버금융 인기 검색 종목에 +(상승), -(하락) 포함시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li><em>1.</em><a href=\"/item/main.nhn?code=005930\" onclick=\"clickcr(this,'boa.list','005930','1',event)\">삼성전자</a><span class=\"up\">81,700</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li> \n",
      "\n",
      "삼성전자\n",
      "81,700\n",
      "['삼성전자', '쌍방울', '카카오', '대원전선', '두산중공업', 'HMM', 'NAVER', '한전산업', '서울식품', '대한전선']\n",
      "['81,700', '1,210', '143,500', '3,580', '24,450', '45,100', '390,500', '11,000', '438', '3,270']\n",
      "['상승', '하락', '하락', '상승', '상승', '상승', '상승', '상승', '상승', '상승']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://finance.naver.com/sise/'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "search_stock = soup.find(\"ul\", id=\"popularItemList\")\n",
    "stock_all = search_stock.find_all(\"li\")\n",
    "\n",
    "# 하나씩 하기\n",
    "print(stock_all[0], \"\\n\")\n",
    "print(stock_all[0].find(\"a\").text)\n",
    "print(stock_all[0].find(\"span\").text)\n",
    "\n",
    "com_all = []\n",
    "price_all = []\n",
    "updown_all = []\n",
    "\n",
    "for one in stock_all :\n",
    "    com_one = one.find(\"a\").text\n",
    "    price_one = one.find(\"span\").text\n",
    "    updown_one = one.find(\"span\", class_=\"blind\").text\n",
    "    \n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)\n",
    "    updown_all.append(updown_one)\n",
    "    \n",
    "print(com_all)\n",
    "print(price_all)\n",
    "print(updown_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.쌍방울1,210하락\n",
      "2.삼성전자81,800상승\n",
      "3.HMM45,050상승\n",
      "4.카카오143,000하락\n",
      "5.두산중공업24,450상승\n",
      "6.대원전선3,555상승\n",
      "7.NAVER391,000상승\n",
      "8.대한전선3,275상승\n",
      "9.대한해운3,670상승\n",
      "10.한전산업11,100상한가\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "rank_1 = soup.find('div', class_='rgt')\n",
    "rank_list = rank_1.find('ul').text.split('\\n')\n",
    "\n",
    "for i in rank_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 네이버금융 인기 검색 종목의 코드 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>com</th>\n",
       "      <th>up_down</th>\n",
       "      <th>price</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>쌍방울</td>\n",
       "      <td>하락</td>\n",
       "      <td>1,050</td>\n",
       "      <td>102280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>상승</td>\n",
       "      <td>81,800</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>카카오</td>\n",
       "      <td>하락</td>\n",
       "      <td>143,000</td>\n",
       "      <td>035720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>HMM</td>\n",
       "      <td>상승</td>\n",
       "      <td>45,050</td>\n",
       "      <td>011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>두산중공업</td>\n",
       "      <td>상승</td>\n",
       "      <td>24,450</td>\n",
       "      <td>034020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>대원전선</td>\n",
       "      <td>상승</td>\n",
       "      <td>3,555</td>\n",
       "      <td>006340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>NAVER</td>\n",
       "      <td>상승</td>\n",
       "      <td>391,000</td>\n",
       "      <td>035420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>한전산업</td>\n",
       "      <td>상한가</td>\n",
       "      <td>11,100</td>\n",
       "      <td>130660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>대한전선</td>\n",
       "      <td>상승</td>\n",
       "      <td>3,275</td>\n",
       "      <td>001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>서울식품</td>\n",
       "      <td>상승</td>\n",
       "      <td>437</td>\n",
       "      <td>004410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank    com up_down    price    code\n",
       "0   1.    쌍방울      하락    1,050  102280\n",
       "1   2.   삼성전자      상승   81,800  005930\n",
       "2   3.    카카오      하락  143,000  035720\n",
       "3   4.    HMM      상승   45,050  011200\n",
       "4   5.  두산중공업      상승   24,450  034020\n",
       "5   6.   대원전선      상승    3,555  006340\n",
       "6   7.  NAVER      상승  391,000  035420\n",
       "7   8.   한전산업     상한가   11,100  130660\n",
       "8   9.   대한전선      상승    3,275  001440\n",
       "9  10.   서울식품      상승      437  004410"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## naver finance 인기 종목\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "all_pop = soup.find(\"ul\", class_=\"lst_pop\").find_all(\"li\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for li in all_pop:\n",
    "    dic = {}\n",
    "    dic[\"rank\"] = li.find(\"em\").text\n",
    "    dic[\"com\"] = li.find(\"a\").text\n",
    "    dic[\"up_down\"] = li.find('span', class_='blind').text\n",
    "    dic[\"price\"] = li.find('span').text\n",
    "    dic[\"code\"] = li.find('a').get(\"onclick\").split(',')[2].strip(\"''\")\n",
    "    all_data.append(dic)\n",
    "    \n",
    "dat = pd.DataFrame(all_data)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자율과제(오늘 수업 복습) - 제출:구글드라이브\n",
    "* Top 종목에 있는 정보 메뉴(상한가, 하한가 등)중 선택해서 가져와서 csv파일로 정리하기."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
